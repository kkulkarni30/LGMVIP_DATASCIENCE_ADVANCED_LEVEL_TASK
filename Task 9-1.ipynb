{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    data=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "        img=~img\n",
    "        if img is not None:\n",
    "            ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "            ctrs,ret=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "            cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            w=int(28)\n",
    "            h=int(28)\n",
    "            maxi=0\n",
    "            for c in cnt:\n",
    "                x,y,w,h=cv2.boundingRect(c)\n",
    "                maxi=max(w*h,maxi)\n",
    "                if maxi==w*h:\n",
    "                    x_max=x\n",
    "                    y_max=y\n",
    "                    w_max=w\n",
    "                    h_max=h\n",
    "            im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10]\n",
    "            im_resize = cv2.resize(im_crop,(28,28))\n",
    "            im_resize=np.reshape(im_resize,(784,1))\n",
    "            data.append(im_resize)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156617\n"
     ]
    }
   ],
   "source": [
    "data=load_images('E://Lets Grow More//Project9//extracted_images//-')\n",
    "len(data)\n",
    "for i in range(0,len(data)):\n",
    "    data[i]=np.append(data[i],['10'])\n",
    "\n",
    "data11=load_images('E://Lets Grow More//Project9//extracted_images//+')\n",
    "for i in range(0,len(data11)):\n",
    "    data11[i]=np.append(data11[i],['11'])\n",
    "\n",
    "data=np.concatenate((data,data11))\n",
    "\n",
    "\n",
    "data0=load_images('E://Lets Grow More//Project9//extracted_images//0')\n",
    "\n",
    "for i in range(0,len(data0)):\n",
    "    data0[i]=np.append(data0[i],['0'])\n",
    "data=np.concatenate((data,data0))\n",
    "\n",
    "data1=load_images('E://Lets Grow More//Project9//extracted_images//1')\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    data1[i]=np.append(data1[i],['1'])\n",
    "data=np.concatenate((data,data1))\n",
    "\n",
    "data2=load_images('E://Lets Grow More//Project9//extracted_images//2')\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    data2[i]=np.append(data2[i],['2'])\n",
    "data=np.concatenate((data,data2))\n",
    "\n",
    "data3=load_images('E://Lets Grow More//Project9//extracted_images//3')\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    data3[i]=np.append(data3[i],['3'])\n",
    "data=np.concatenate((data,data3))\n",
    "\n",
    "data4=load_images('E://Lets Grow More//Project9//extracted_images//4')\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    data4[i]=np.append(data4[i],['4'])\n",
    "data=np.concatenate((data,data4))\n",
    "\n",
    "data5=load_images('E://Lets Grow More//Project9//extracted_images//5')\n",
    "\n",
    "for i in range(0,len(data5)):\n",
    "    data5[i]=np.append(data5[i],['5'])\n",
    "data=np.concatenate((data,data5))\n",
    "\n",
    "data6=load_images('E://Lets Grow More//Project9//extracted_images//6')\n",
    "\n",
    "for i in range(0,len(data6)):\n",
    "    data6[i]=np.append(data6[i],['6'])\n",
    "data=np.concatenate((data,data6))\n",
    "\n",
    "data7=load_images('E://Lets Grow More//Project9//extracted_images//7')\n",
    "\n",
    "for i in range(0,len(data7)):\n",
    "    data7[i]=np.append(data7[i],['7'])\n",
    "data=np.concatenate((data,data7))\n",
    "\n",
    "data8=load_images('E://Lets Grow More//Project9//extracted_images//8')\n",
    "\n",
    "for i in range(0,len(data8)):\n",
    "    data8[i]=np.append(data8[i],['8'])\n",
    "data=np.concatenate((data,data8))\n",
    "\n",
    "data9=load_images('E://Lets Grow More//Project9//extracted_images//9')\n",
    "\n",
    "for i in range(0,len(data9)):\n",
    "    data9[i]=np.append(data9[i],['9'])\n",
    "data=np.concatenate((data,data9))\n",
    "\n",
    "data12=load_images('E://Lets Grow More//Project9//extracted_images//times')\n",
    "\n",
    "for i in range(0,len(data12)):\n",
    "    data12[i]=np.append(data12[i],['12'])\n",
    "data=np.concatenate((data,data12))\n",
    "print(len(data))\n",
    "\n",
    "df=pd.DataFrame(data,index=None)\n",
    "df.to_csv('train_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76d7c06053c3456e5600312cec90888656fc0ed30c03d8425b9dac6e4fc8e014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
